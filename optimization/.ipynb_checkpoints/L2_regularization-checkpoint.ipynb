{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lecture summary of the regularization's lecture*\n",
    "\n",
    "1 ) Regularization helps preventing overfitting <br>\n",
    "2 ) L1 \"sparse\" the model, it adds zeros to the W parameter which \"compress\" the model <br>\n",
    "3 ) Lambda is the regularization parameter\n",
    "4 ) Lambda big => W small => Z has a smaller range of value => activation before last layer is smaller => linearity due to the activation function (see tanh and sigmoid !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[0, :].min() - 1, X[0, :].max() + 1\n",
    "    y_min, y_max = X[1, :].min() - 1, X[1, :].max() + 1\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole grid\n",
    "    Z = model(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.ylabel('x2')\n",
    "    plt.xlabel('x1')\n",
    "    plt.scatter(X[0, :], X[1, :], c=y, cmap=plt.cm.Spectral)\n",
    "    \n",
    "\n",
    "def load_planar_dataset():\n",
    "    np.random.seed(1)\n",
    "    m = 400 # number of examples\n",
    "    N = int(m/2) # number of points per class\n",
    "    D = 2 # dimensionality\n",
    "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
    "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
    "    a = 4 # maximum ray of the flower\n",
    "\n",
    "    for j in range(2):\n",
    "        ix = range(N*j,N*(j+1))\n",
    "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
    "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        Y[ix] = j\n",
    "        \n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def load_extra_datasets():  \n",
    "    N = 200\n",
    "    noisy_circles = sklearn.datasets.make_circles(n_samples=N, factor=.5, noise=.3)\n",
    "    noisy_moons = sklearn.datasets.make_moons(n_samples=N, noise=.2)\n",
    "    blobs = sklearn.datasets.make_blobs(n_samples=N, random_state=5, n_features=2, centers=6)\n",
    "    gaussian_quantiles = sklearn.datasets.make_gaussian_quantiles(mean=None, cov=0.5, n_samples=N, n_features=2, n_classes=2, shuffle=True, random_state=None)\n",
    "    no_structure = np.random.rand(N, 2), np.random.rand(N, 2)\n",
    "    \n",
    "    return noisy_circles, noisy_moons, blobs, gaussian_quantiles, no_structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z): \n",
    "    '''\n",
    "        apply the sigmoid function on Z \n",
    "        output : \n",
    "            s : Z: -> sigmoid(Z)\n",
    "            cache : a tuple containing the parameter Z\n",
    "    '''\n",
    "    \n",
    "    s = 1 / (1+np.exp(-Z))\n",
    "    cache = (Z,)\n",
    "    \n",
    "    return s, cache \n",
    "\n",
    "\n",
    "def linear(A, W, b): \n",
    "    '''\n",
    "        return the linear operation \n",
    "        output : \n",
    "            s : the linear operation \n",
    "            cache : all parameters used for the computation inside a tuple\n",
    "    '''\n",
    "    \n",
    "    assert W.shape[1] == A.shape[0] \n",
    "    assert b.shape[0] == W.shape[0]\n",
    "    \n",
    "    s = W.dot(A) + b\n",
    "    cache = (A, W, b) \n",
    "    \n",
    "    return s, cache\n",
    "\n",
    "\n",
    "def relu(Z): \n",
    "    '''\n",
    "        return the relu operation\n",
    "        output : \n",
    "            s : the relu operation \n",
    "            cache : Z inside a tuple\n",
    "    '''\n",
    "    \n",
    "    s = np.maximum(Z, 0) \n",
    "    cache = (Z,)\n",
    "    return s, cache \n",
    "\n",
    "def relu_derivative(Z): \n",
    "    '''\n",
    "        return the derivative of the relu function \n",
    "        output : \n",
    "            A : the derivative of the relu function \n",
    "    '''\n",
    "    A = Z.copy()\n",
    "    A[A > 0] = 1 \n",
    "    A[A <= 0] = 0\n",
    "    \n",
    "    return A\n",
    "\n",
    "def compute_cost(A, Y): \n",
    "    '''\n",
    "        return the computation of the cost function \n",
    "    '''\n",
    "    assert A.shape == Y.shape\n",
    "    m = A.shape[1] \n",
    "    return (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A)))\n",
    "\n",
    "    \n",
    "def initialize_parameters(X, nb_neurones): \n",
    "    '''\n",
    "        return a dictionary containing all initialized parameters for all layers \n",
    "        ouput : \n",
    "            the dictionary of parameters\n",
    "    '''\n",
    "    parameters = {} \n",
    "    \n",
    "    # get number of samples \n",
    "    m = X.shape[1]\n",
    "    # get number of layers \n",
    "    l = len(nb_neurones)\n",
    "    \n",
    "    for i in range(l): \n",
    "        # init using the He method\n",
    "        print(f\"Initializing for layer : {i}\")\n",
    "        if i == 0: \n",
    "            W = np.random.randn(nb_neurones[i], X.shape[0]) * np.sqrt(2/nb_neurones[i])\n",
    "        else: \n",
    "            W = np.random.randn(nb_neurones[i], parameters[f\"W{i}\"].shape[0]) * np.sqrt(2/nb_neurones[i])\n",
    "    \n",
    "        b = np.random.randn(nb_neurones[i], 1) * 0.01\n",
    "        parameters[f\"W{i+1}\"] = W \n",
    "        parameters[f\"b{i+1}\"] = b\n",
    "        \n",
    "    print(\"Successfully initialized parameters for the entire network\")\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_pass(X, parameters, Y, regularization, regulizer): \n",
    "    '''\n",
    "        Entire forward propagation across all layers of the network\n",
    "        output : \n",
    "            grads : a dictionnary of all gradients \n",
    "            cache : a dictionnary of all parameters used\n",
    "    '''\n",
    "    l = len(parameters) // 2 \n",
    "    grads = {}\n",
    "    all_cache = {}\n",
    "    \n",
    "    A = X\n",
    "    all_cache[\"A0\"] = A\n",
    "    for i in range(l): \n",
    "        W = parameters[f\"W{i+1}\"] \n",
    "        b = parameters[f\"b{i+1}\"] \n",
    "        \n",
    "        if i != l-1: \n",
    "            # use the relu activation \n",
    "            Z, cache = linear(A, W, b)\n",
    "            \n",
    "            all_cache[f\"W{i+1}\"] = W\n",
    "            all_cache[f\"b{i+1}\"] = b \n",
    "            \n",
    "            #activation \n",
    "            A, cache = relu(Z)\n",
    "            all_cache[f\"Z{i+1}\"] = Z \n",
    "            all_cache[f\"A{i+1}\"] = A\n",
    "\n",
    "        \n",
    "        else: \n",
    "            # last layer has to use the sigmoid activation \n",
    "            Z, cache = linear(A, W, b)     \n",
    "            \n",
    "            \n",
    "            all_cache[f\"W{i+1}\"] = W\n",
    "            all_cache[f\"b{i+1}\"] = b \n",
    "\n",
    "            # activation \n",
    "            A, cache = sigmoid(Z)\n",
    "            all_cache[f\"Z{i+1}\"] = Z \n",
    "            all_cache[f\"A{i+1}\"] = A\n",
    "        \n",
    "    \n",
    "    # compute cost\n",
    "    if regularization == \"L2\": \n",
    "        cost = compute_cost2(A, Y, parameters, regularization, regulizer)\n",
    "    else:  \n",
    "        # no regularization\n",
    "        cost = compute_cost(A, Y) \n",
    "    return cost, all_cache\n",
    "\n",
    "def backward_pass(parameters, cache, Y, l):\n",
    "    '''\n",
    "        return all gradients \n",
    "        output : \n",
    "            grads : a dictionary containing all gradients\n",
    "    '''\n",
    "    m = Y.shape[1]\n",
    "    grads = {} \n",
    "\n",
    "    for i in reversed(range(l)): \n",
    "        if i == l-1: \n",
    "            dZ = cache[f\"A{i+1}\"] - Y\n",
    "        else: \n",
    "            dZ = cache[f\"W{i+2}\"].T.dot(dZ) * relu_derivative(cache[f\"Z{i+1}\"]) \n",
    "        \n",
    "        dW = (1/m) * dZ.dot(cache[f\"A{i}\"].T)\n",
    "        db = (1/m) * np.sum(dZ, keepdims=True, axis=1)\n",
    "\n",
    "        # save gradients \n",
    "        grads[f\"dZ{i+1}\"] = dZ\n",
    "        grads[f\"dW{i+1}\"] = dW \n",
    "        grads[f\"db{i+1}\"] = db\n",
    "            \n",
    "    return grads\n",
    "    \n",
    "def update_parameters(parameters, grads, learning_rate): \n",
    "    for param in parameters:\n",
    "        # takes a long time but do it once ! \n",
    "        assert parameters[param].shape == grads[f\"d{param}\"].shape\n",
    "        parameters[param] = parameters[param] - learning_rate * grads[f\"d{param}\"]\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def predict(X, parameters, Y_true, regularization, regulizer): \n",
    "    A = forward_pass(X, parameters, Y_true, regularization, regulizer)[1][f\"A{len(parameters) // 2}\"]\n",
    "    pred = A\n",
    "    pred[pred >= 0.5] = 1\n",
    "    pred[pred < 0.5] = 0\n",
    "\n",
    "    print(f\"Accuracy : {(pred == Y_true).mean() * 100} % \")\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating our compute_cost function with a regularization parameter\n",
    "\n",
    "# def frobenius_norm(W): \n",
    "#     '''\n",
    "#         apply the frobenius norm on the weight matrix W \n",
    "#         Argument : \n",
    "#             W : (n_l-1, n_l) \n",
    "#     '''\n",
    "    \n",
    "#     norm = 0\n",
    "    \n",
    "#     for i in range(W.shape[0]): \n",
    "#         for j in range(W.shape[1]): \n",
    "#             norm += np.power(W[i,j], 2)\n",
    "            \n",
    "#     return norm\n",
    "\n",
    "def compute_cost2(A, Y, parameters, regularization=\"L2\", regulizer=0.01): \n",
    "    '''\n",
    "        return the computation of the cost function \n",
    "        Argument : \n",
    "            parameters : the parameters \n",
    "            regularization : the regularization type \n",
    "            regulizer : the regularization \"lambda\" parameter\n",
    "    '''\n",
    "    assert A.shape == Y.shape\n",
    "    m = A.shape[1] \n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A)))\n",
    "    L = len(parameters) // 2\n",
    "#     if regularization == \"L2\": \n",
    "#         reg = 0 \n",
    "#         for l in range(L): \n",
    "#             reg += np.sum(np.square(parameters[f\"W{l+1}\"]))\n",
    "#         return cost + (regulizer * reg / 2*m)\n",
    "    \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass with new derivatives\n",
    "\n",
    "def backward_pass2(parameters, cache, Y, l, regulizer):\n",
    "    '''\n",
    "        return all gradients \n",
    "        output : \n",
    "            grads : a dictionary containing all gradients\n",
    "    '''\n",
    "    m = Y.shape[1]\n",
    "    grads = {} \n",
    "\n",
    "    for i in reversed(range(l)): \n",
    "        if i == l-1: \n",
    "            dZ = cache[f\"A{i+1}\"] - Y\n",
    "        else: \n",
    "            dZ = cache[f\"W{i+2}\"].T.dot(dZ) * relu_derivative(cache[f\"Z{i+1}\"]) \n",
    "        \n",
    "        dW = (1/m) * dZ.dot(cache[f\"A{i}\"].T) + (regulizer * cache[f\"W{i+1}\"]/m)\n",
    "        db = (1/m) * np.sum(dZ, keepdims=True, axis=1)\n",
    "\n",
    "        # save gradients \n",
    "        grads[f\"dZ{i+1}\"] = dZ\n",
    "        grads[f\"dW{i+1}\"] = dW \n",
    "        grads[f\"db{i+1}\"] = db\n",
    "            \n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_nn(X, Y, nb_neurones, learning_rate, epochs, print_t=False, regularization=None, regulizer=0.01): \n",
    "    \n",
    "    # init parameters \n",
    "    parameters = initialize_parameters(X, nb_neurones)\n",
    "    cost_history = []\n",
    "    for epoch in range(epochs): \n",
    "        # forward pass\n",
    "        cost, cache = forward_pass(X, parameters, Y, regularization, regulizer) \n",
    "        cost_history.append(cost)\n",
    "        if print_t and epoch % 100 == 0: \n",
    "            print(f\"Cost value at {epoch} : {cost}\")\n",
    "        # backward propagation \n",
    "        if regularization == \"L2\":\n",
    "            grads = backward_pass2(parameters, cache, Y, len(nb_neurones), regulizer)\n",
    "        else: \n",
    "            grads = backward_pass(parameters, cache, Y, len(nb_neurones))\n",
    "        prameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "    print(\"Training accuracy : \") \n",
    "    predictions = predict(X, parameters, Y, regularization, regulizer)\n",
    "            \n",
    "    plt.plot(range(epochs), cost_history) \n",
    "    plt.show() \n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (2, 400)\n",
      "Y shape : (1, 400)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_planar_dataset()\n",
    "print(f\"X shape : {X.shape}\") \n",
    "print(f\"Y shape : {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X.T, Y.T, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (320, 2)\n",
      "X_test shape : (80, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape : {X_train.shape}\")\n",
    "print(f\"X_test shape : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training a basic neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing for layer : 0\n",
      "Initializing for layer : 1\n",
      "Initializing for layer : 2\n",
      "Successfully initialized parameters for the entire network\n",
      "Training accuracy : \n",
      "Accuracy : 90.9375 % \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy :\n",
      "Accuracy : 82.5 % \n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      "  1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# parameters = l_nn(X_train.T, Y_train.T, [10, 20, 1], 0.01, 20000, print_t=False)\n",
    "# print(\"Testing accuracy :\") \n",
    "# acc = predict(X_test.T, parameters, Y_test.T) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train.T - X_train.T.std()) / X_train.T.mean() \n",
    "X_test = (X_test.T - X_test.T.std()) / X_test.T.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 320)\n",
      "(320, 1)\n",
      "Initializing for layer : 0\n",
      "Initializing for layer : 1\n",
      "Initializing for layer : 2\n",
      "Successfully initialized parameters for the entire network\n",
      "Cost value at 0 : nan\n",
      "Cost value at 100 : 0.6862217665702413\n",
      "Cost value at 200 : 0.6861780148792282\n",
      "Cost value at 300 : 0.6861590738302497\n",
      "Cost value at 400 : 0.6861468212124282\n",
      "Cost value at 500 : 0.686137552495109\n",
      "Cost value at 600 : 0.6861299190302597\n",
      "Cost value at 700 : 0.686123295405666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valentin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\valentin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\valentin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cost value at 800 : 0.686117346471686\n",
      "Cost value at 900 : 0.6861118741672675\n",
      "Cost value at 1000 : 0.6861067528370984\n",
      "Cost value at 1100 : 0.6861018983402789\n",
      "Cost value at 1200 : 0.6860972518883811\n",
      "Cost value at 1300 : 0.6861719763383863\n",
      "Cost value at 1400 : 0.6861237503937542\n",
      "Cost value at 1500 : 0.6861124738110803\n",
      "Cost value at 1600 : 0.6861074497790174\n",
      "Cost value at 1700 : 0.6861028962017075\n",
      "Cost value at 1800 : 0.6860983692765532\n",
      "Cost value at 1900 : 0.6860938684425145\n",
      "Cost value at 2000 : 0.6860893932729341\n",
      "Cost value at 2100 : 0.6860849423946191\n",
      "Cost value at 2200 : 0.6860805145092272\n",
      "Cost value at 2300 : 0.6860761083780744\n",
      "Cost value at 2400 : 0.6860717228145998\n",
      "Cost value at 2500 : 0.686067356681617\n",
      "Cost value at 2600 : 0.6860630088887143\n",
      "Cost value at 2700 : 0.6860467537318011\n",
      "Cost value at 2800 : 0.6860419222182375\n",
      "Cost value at 2900 : 0.6860372697788498\n",
      "Cost value at 3000 : 0.6860327599182012\n",
      "Cost value at 3100 : 0.6860283653514165\n",
      "Cost value at 3200 : 0.6860240652007393\n",
      "Cost value at 3300 : 0.6860249996658764\n",
      "Cost value at 3400 : 0.6860202802478842\n",
      "Cost value at 3500 : 0.6860157064634589\n",
      "Cost value at 3600 : 0.686011250060283\n",
      "Cost value at 3700 : 0.6860068895049012\n",
      "Cost value at 3800 : 0.6860174197415275\n",
      "Cost value at 3900 : 0.6860031792128604\n",
      "Cost value at 4000 : 0.6859985185132452\n",
      "Cost value at 4100 : 0.6859939811098031\n",
      "Cost value at 4200 : 0.6859895439011066\n",
      "Cost value at 4300 : 0.6859851890212902\n",
      "Cost value at 4400 : 0.6859859954513264\n",
      "Cost value at 4500 : 0.6859812185568418\n",
      "Cost value at 4600 : 0.6859765761379468\n",
      "Cost value at 4700 : 0.6859720421904172\n",
      "Cost value at 4800 : 0.6859675968175983\n",
      "Cost value at 4900 : 0.6859632244786361\n",
      "Cost value at 5000 : 0.685965989791848\n",
      "Cost value at 5100 : 0.6859645109333888\n",
      "Cost value at 5200 : 0.6859631591875669\n",
      "Cost value at 5300 : 0.6859619121907218\n",
      "Cost value at 5400 : 0.6859607527518783\n",
      "Cost value at 5500 : 0.6859596674011673\n",
      "Cost value at 5600 : 0.6859636083619377\n",
      "Cost value at 5700 : 0.6859621586386334\n",
      "Cost value at 5800 : 0.6859608307811232\n",
      "Cost value at 5900 : 0.6859596036475314\n",
      "Cost value at 6000 : 0.6859584609193807\n",
      "Cost value at 6100 : 0.6859573897677724\n",
      "Cost value at 6200 : 0.6859612798863797\n",
      "Cost value at 6300 : 0.6859598518220926\n",
      "Cost value at 6400 : 0.6859585417745876\n",
      "Cost value at 6500 : 0.6859573294800447\n",
      "Cost value at 6600 : 0.6859561992521231\n",
      "Cost value at 6700 : 0.6859551387287145\n",
      "Cost value at 6800 : 0.6859589912205893\n",
      "Cost value at 6900 : 0.6859575790606889\n",
      "Cost value at 7000 : 0.6859562821189378\n",
      "Cost value at 7100 : 0.6859550807575826\n",
      "Cost value at 7200 : 0.6859539597438433\n",
      "Cost value at 7300 : 0.6859529070521284\n",
      "Cost value at 7400 : 0.685956749064692\n",
      "Cost value at 7500 : 0.6859553464256772\n",
      "Cost value at 7600 : 0.6859540573436046\n",
      "Cost value at 7700 : 0.685952862540103\n",
      "Cost value at 7800 : 0.6859517470451559\n",
      "Cost value at 7900 : 0.6859506990295245\n",
      "Cost value at 8000 : 0.6859545524149075\n",
      "Cost value at 8100 : 0.6859531530981318\n",
      "Cost value at 8200 : 0.6859518667684341\n",
      "Cost value at 8300 : 0.6859506742536493\n",
      "Cost value at 8400 : 0.685949560664788\n",
      "Cost value at 8500 : 0.6859485142349881\n",
      "Cost value at 8600 : 0.6859524004987803\n",
      "Cost value at 8700 : 0.6859509983921486\n",
      "Cost value at 8800 : 0.685949709777982\n",
      "Cost value at 8900 : 0.6859485153403336\n",
      "Cost value at 9000 : 0.6859474000925885\n",
      "Cost value at 9100 : 0.6859463521984827\n",
      "Cost value at 9200 : 0.6859502834021943\n",
      "Cost value at 9300 : 0.6859488734487285\n",
      "Cost value at 9400 : 0.68594757839407\n",
      "Cost value at 9500 : 0.6859463785642246\n",
      "Cost value at 9600 : 0.6859452587250975\n",
      "Cost value at 9700 : 0.6859442068607966\n",
      "Cost value at 9800 : 0.6859482214377092\n",
      "Cost value at 9900 : 0.6859467961243784\n",
      "Cost value at 10000 : 0.6859454884868447\n",
      "Cost value at 10100 : 0.685944278151296\n",
      "Cost value at 10200 : 0.6859431494088448\n",
      "Cost value at 10300 : 0.6859420898975169\n",
      "Cost value at 10400 : 0.6859410897362843\n",
      "Cost value at 10500 : 0.6859447607650943\n",
      "Cost value at 10600 : 0.6859434348176372\n",
      "Cost value at 10700 : 0.6859422092373388\n",
      "Cost value at 10800 : 0.6859410676160336\n",
      "Cost value at 10900 : 0.685939997083123\n",
      "Cost value at 11000 : 0.6859389873795676\n",
      "Cost value at 11100 : 0.6859427694989683\n",
      "Cost value at 11200 : 0.685941419032546\n",
      "Cost value at 11300 : 0.6859401731090093\n",
      "Cost value at 11400 : 0.685939014358631\n",
      "Cost value at 11500 : 0.6859379292163909\n",
      "Cost value at 11600 : 0.6859369069086386\n",
      "Cost value at 11700 : 0.6859408262041357\n",
      "Cost value at 11800 : 0.6859394442225464\n",
      "Cost value at 11900 : 0.6859381722785397\n",
      "Cost value at 12000 : 0.6859369917024399\n",
      "Cost value at 12100 : 0.6859358880128611\n",
      "Cost value at 12200 : 0.6859348497601836\n",
      "Cost value at 12300 : 0.6859338677550345\n",
      "Cost value at 12400 : 0.6859375236502828\n",
      "Cost value at 12500 : 0.6859362182460778\n",
      "Cost value at 12600 : 0.685935009733017\n",
      "Cost value at 12700 : 0.6859338824030207\n",
      "Cost value at 12800 : 0.6859328239080161\n",
      "Cost value at 12900 : 0.6859318243865141\n",
      "Cost value at 13000 : 0.6859356648790236\n",
      "Cost value at 13100 : 0.6859343171878827\n",
      "Cost value at 13200 : 0.6859330735774253\n",
      "Cost value at 13300 : 0.6859319166949945\n",
      "Cost value at 13400 : 0.6859308330104421\n",
      "Cost value at 13500 : 0.6859298117839403\n",
      "Cost value at 13600 : 0.6859288443659594\n",
      "Cost value at 13700 : 0.6859324677535812\n",
      "Cost value at 13800 : 0.6859311814600227\n",
      "Cost value at 13900 : 0.6859299888476038\n",
      "Cost value at 14000 : 0.6859288748662671\n",
      "Cost value at 14100 : 0.6859278276575043\n",
      "Cost value at 14200 : 0.6859268377313364\n",
      "Cost value at 14300 : 0.6859306869740791\n",
      "Cost value at 14400 : 0.685929347834341\n",
      "Cost value at 14500 : 0.6859281113182322\n",
      "Cost value at 14600 : 0.6859269603358614\n",
      "Cost value at 14700 : 0.6859258815690488\n",
      "Cost value at 14800 : 0.6859248644409079\n",
      "Cost value at 14900 : 0.6859239004293394\n",
      "Cost value at 15000 : 0.6859275923308732\n",
      "Cost value at 15100 : 0.6859263008532364\n",
      "Cost value at 15200 : 0.6859251038920355\n",
      "Cost value at 15300 : 0.6859239861632056\n",
      "Cost value at 15400 : 0.6859229356467045\n",
      "Cost value at 15500 : 0.6859219427363348\n",
      "Cost value at 15600 : 0.6859209996492353\n",
      "Cost value at 15700 : 0.6859245621673434\n",
      "Cost value at 15800 : 0.6859233088212755\n",
      "Cost value at 15900 : 0.6859221436777647\n",
      "Cost value at 16000 : 0.6859210528049406\n",
      "Cost value at 16100 : 0.6859200251779778\n",
      "Cost value at 16200 : 0.6859190519408245\n",
      "Cost value at 16300 : 0.6859229128615842\n",
      "Cost value at 16400 : 0.6859215867907416\n",
      "Cost value at 16500 : 0.6859203636695752\n",
      "Cost value at 16600 : 0.6859192238426738\n",
      "Cost value at 16700 : 0.685918154401334\n",
      "Cost value at 16800 : 0.6859171450817163\n",
      "Cost value at 16900 : 0.6859161876051907\n",
      "Cost value at 17000 : 0.6859199628327696\n",
      "Cost value at 17100 : 0.6859186671561086\n",
      "Cost value at 17200 : 0.6859174666827023\n",
      "Cost value at 17300 : 0.6859163458735088\n",
      "Cost value at 17400 : 0.6859152925587885\n",
      "Cost value at 17500 : 0.685914297028282\n",
      "Cost value at 17600 : 0.685913351425837\n",
      "Cost value at 17700 : 0.6859170743758974\n",
      "Cost value at 17800 : 0.6859157978578776\n",
      "Cost value at 17900 : 0.6859146133082175\n",
      "Cost value at 18000 : 0.6859135058850667\n",
      "Cost value at 18100 : 0.6859124639230905\n",
      "Cost value at 18200 : 0.6859114780921923\n",
      "Cost value at 18300 : 0.6859105408279069\n",
      "Cost value at 18400 : 0.6859142393981976\n",
      "Cost value at 18500 : 0.6859129746702834\n",
      "Cost value at 18600 : 0.6859117999309755\n",
      "Cost value at 18700 : 0.6859107007460438\n",
      "Cost value at 18800 : 0.6859096657525182\n",
      "Cost value at 18900 : 0.6859086858497881\n",
      "Cost value at 19000 : 0.6859077536506141\n",
      "Cost value at 19100 : 0.6859114546232227\n",
      "Cost value at 19200 : 0.6859101947901061\n",
      "Cost value at 19300 : 0.6859090241187001\n",
      "Cost value at 19400 : 0.6859079283210993\n",
      "Cost value at 19500 : 0.6859068961530772\n",
      "Cost value at 19600 : 0.6859059186058802\n",
      "Cost value at 19700 : 0.6859049883644806\n",
      "Cost value at 19800 : 0.6859087183696904\n",
      "Cost value at 19900 : 0.685907456718566\n",
      "Training accuracy : \n",
      "Accuracy : 50.625 % \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df3Rc5X3n8fdnRpJtGWMbbFNiG2yCtImhjiECEtyEH1mICNuQbhvAKTn9Cd10vVvKWVo42cOmbnNayOlpQuNd1qVs054QoDQBJzUYmlJCCQ4WCQYsY6yYHxY2tjDGP/APSTPf/eNe2ePRSBpJIwu4n9c5czzz3GfufZ478nzmPs/cuYoIzMwsm3Lj3QAzMxs/DgEzswxzCJiZZZhDwMwswxwCZmYZVjfeDRiOGTNmxLx588a7GWZm7ynPPPPMmxExs9Ky91QIzJs3j7a2tvFuhpnZe4qkVwda5uEgM7MMcwiYmWWYQ8DMLMOqCgFJrZI2SuqQdNMAda6U1C5pvaS7S8pvlfRCeruqwvP+WtK+kXfBzMxGasiJYUl5YDlwCdAJrJW0MiLaS+o0ATcDiyNil6RZafnlwNnAImAC8LikhyJiT7q8BZhW4z6ZmVmVqjkSOBfoiIjNEdEN3ANcUVbnWmB5ROwCiIgdafkC4PGI6I2Id4B1QCscDpevAX80+m6YmdlIVBMCs4EtJY8707JSzUCzpCclrZHUmpavAy6T1ChpBnARMDddthRYGRHbBtu4pOsktUlq6+rqqqK5ZmZWrWrOE1CFsvLfn64DmoALgTnAE5LOjIhHJJ0D/BjoAp4CeiV9APh8Wn9QEbECWAHQ0tIyot+9/t7POnnnUIFrPnbqSJ5uZva+Vc2RQCdHPr1D8ia/tUKdByOiJyJeBjaShAIR8dWIWBQRl5AEyibgLOB0oEPSK0CjpI5R9WQQK5/dyn1tW4auaGaWMdWEwFqgSdJ8SQ3A1cDKsjoPkAz1kA77NAObJeUlnZiWLwQWAo9ExD9HxC9ExLyImAfsj4jTa9MlMzOr1pDDQRHRK2kpsBrIA3dFxHpJy4C2iFiZLrtUUjtQAG6MiJ2SJpIMDQHsAa6JiN6x6oyZmQ1PVb8dFBGrgFVlZbeU3A/ghvRWWucgyTeEhlr/cdW0YzR8FU0zs/4yccZweiRiZmZlMhECZmZWmUPAzCzDHAJmZhmWmRCIfue3mZlZJkLA08JmZpVlIgTMzKwyh4CZWYZlJgR8spiZWX+ZCAGfK2ZmVlkmQsDMzCpzCJiZZVhmQsBzAmZm/WUmBMzMrL+MhIBnhs3MKqkqBCS1StooqUPSTQPUuVJSu6T1ku4uKb9V0gvp7aqS8r+VtE7Sc5LulzTm1xQwM7OjDRkCkvLAcuAykgvELJG0oKxOE3AzsDgizgCuT8svB84GFgHnATdKOj592h9GxEciYiHwGrC0Nl0yM7NqVXMkcC7QERGbI6IbuAe4oqzOtcDyiNgFEBE70vIFwOMR0RsR7wDrgNa0zh4AJVd8mQRj+wtvnhc2M+uvmhCYDWwpedyZlpVqBpolPSlpjaTWtHwdcJmkxvQC9BcBc/ueJOn/AW8AHwL+eoR9GJJPFjMzq6yaEKj0Flr+wboOaAIuBJYAd0qaFhGPkFyb+MfAd4CngMMXmo+I3wI+AGwArqICSddJapPU1tXVVUVzzcysWtWEQCcln96BOcDWCnUejIieiHgZ2EgSCkTEVyNiUURcQhIom0qfGBEF4F7gVyttPCJWRERLRLTMnDmzmj6ZmVmVqgmBtUCTpPmSGoCrgZVldR4gGeohHfZpBjZLyks6MS1fCCwEHlHi9LRcwC8DL9aiQwMJny1mZtZP3VAVIqJX0lJgNZAH7oqI9ZKWAW0RsTJddqmkdqAA3BgROyVNBJ5I3ufZA1yTri8HfCv9ppBI5g6+NBYdBJ8lYGY2kCFDACAiVpGM7ZeW3VJyP4Ab0ltpnYMk3xAqX18RWDyC9pqZWQ1l5IxhMzOrxCFgZpZhDgEzswzLRAj4ZDEzs8oyEQJmZlaZQ8DMLMMyEwI+V8zMrL9MhIB8upiZWUWZCAEzM6vMIWBmlmGZCYHwZWXMzPrJRAj4PAEzs8oyEQJmZlaZQ8DMLMMcAmZmGZaZEPDJYmZm/VUVApJaJW2U1CHppgHqXCmpXdJ6SXeXlN8q6YX0dlVJ+bfTdb4g6S5J9aPvzkDtH6s1m5m9tw0ZApLywHLgMpKrhC2RtKCsThNwM7A4Is4Ark/LLwfOBhYB5wE3ppeUBPg28CHgF4FJwO/WokNmZla9ao4EzgU6ImJzRHQD9wBXlNW5FlgeEbsAImJHWr4AeDwieiPiHZJrCbemdVZFCngamDP67piZ2XBUEwKzgS0ljzvTslLNQLOkJyWtkdSalq8DLpPUKGkGcBEwt/SJ6TDQF4GHK21c0nWS2iS1dXV1VdHcyjwlYGbWXzUXmq80ol7+nloHNAEXknyif0LSmRHxiKRzgB8DXcBTQG/Zc/838KOIeKLSxiNiBbACoKWlZUTv5f4BOTOzyqo5Eujk6E/vc4CtFeo8GBE9EfEysJEkFIiIr0bEooi4hCRQNvU9SdL/AmYCN4y8C2ZmNlLVhMBaoEnSfEkNwNXAyrI6D5AM9ZAO+zQDmyXlJZ2Yli8EFgKPpI9/F/g0sCQiirXojJmZDc+Qw0ER0StpKbAayAN3RcR6ScuAtohYmS67VFI7UABujIidkiaSDA0B7AGuiYi+4aA7gFeBp9Ll342IZTXun5mZDaKaOQEiYhWwqqzslpL7QTKkc0NZnYMk3xCqtM6qtl0r4bPFzMz6ycYZw54XNjOrKBshYGZmFTkEzMwyLDMh4BkBM7P+MhECnhIwM6ssEyFgZmaVOQTMzDIsOyHgSQEzs34yEQLyVWXMzCrKRAiYmVllDgEzswxzCJiZZVhmQsDzwmZm/WUiBDwtbGZWWSZCwMzMKnMImJllWFUhIKlV0kZJHZJuGqDOlZLaJa2XdHdJ+a2SXkhvV5WUL03XF+klKceULypjZtbfkFf3kpQHlgOXkFxQfq2klRHRXlKnCbgZWBwRuyTNSssvB84GFgETgMclPRQRe4AngR8A/1bbLlXqw1hvwczsvamaI4FzgY6I2BwR3cA9wBVlda4FlkfELoCI2JGWLwAej4jeiHgHWAe0pnV+FhGv1KAPZmY2QtWEwGxgS8njzrSsVDPQLOlJSWsktabl64DLJDWmQz4XAXOH00BJ10lqk9TW1dU1nKeamdkQqrnYe6XBlPIB9jqgCbgQmAM8IenMiHhE0jnAj4Eu4CmgdzgNjIgVwAqAlpaWEQ/se0bAzKy/ao4EOjn60/scYGuFOg9GRE9EvAxsJAkFIuKrEbEoIi4hCZRNo2/28HhKwMyssmpCYC3QJGm+pAbgamBlWZ0HSIZ6SId9moHNkvKSTkzLFwILgUdq1XgzMxudIUMgInqBpcBqYANwX0Ssl7RM0mfTaquBnZLagceAGyNiJ1BPMjTUTjKkc026PiT9d0mdJEcWz0m6s9adMzOzwVUzJ0BErAJWlZXdUnI/gBvSW2mdgyTfEKq0ztuB24fZXjMzq6HMnDHsc8XMzPrLRAj4ymJmZpVlIgTMzKwyh4CZWYZlJgTCp4uZmfWTiRDwjICZWWWZCAEzM6vMIWBmlmEOATOzDMtMCPhkMTOz/rIRAp4ZNjOrKBshYGZmFTkEzMwyLDMh4DkBM7P+MhEC8qSAmVlFmQgBMzOrrKoQkNQqaaOkDkk3DVDnSkntktZLuruk/FZJL6S3q0rK50v6iaRNku5NL11pZmbH0JAhICkPLAcuI7lK2BJJC8rqNAE3A4sj4gzg+rT8cuBsYBFwHnCjpOPTp90K/FVENAG7gN+pSY/MzKxq1RwJnAt0RMTmiOgG7gGuKKtzLbA8InYBRMSOtHwB8HhE9EbEO8A6oFXJVV4uBu5P630L+NzoujIwX1PGzKyyakJgNrCl5HFnWlaqGWiW9KSkNZJa0/J1wGWSGiXNAC4C5gInAm/3XXR+gHUCIOk6SW2S2rq6uqrrlZmZVaWaC81X+hxd/oXLOqAJuBCYAzwh6cyIeETSOcCPgS7gKaC3ynUmhRErgBUALS0t/qKnmVkNVXMk0Eny6b3PHGBrhToPRkRPRLwMbCQJBSLiqxGxKCIuIXnz3wS8CUyTVDfIOs3MbIxVEwJrgab02zwNwNXAyrI6D5AM9ZAO+zQDmyXlJZ2Yli8EFgKPREQAjwG/lj7/N4AHR9uZwYTPFjMz62fI4aCI6JW0FFgN5IG7ImK9pGVAW0SsTJddKqkdKAA3RsROSRNJhoYA9gDXlMwD/DFwj6Q/A34G/G2tO9fH88JmZpVVMydARKwCVpWV3VJyP4Ab0ltpnYMk3xCqtM7NJN88MjOzceIzhs3MMiwzIeAZATOz/jIRAj5ZzMysskyEgJmZVeYQMDPLsMyEgE8TMDPrLxMh4IvKmJlVlokQMDOzyhwCZmYZ5hAwM8uwzIRA+HQxM7N+MhECPlnMzKyyTISAmZlV5hAwM8uwzISATxYzM+uvqhCQ1Cppo6QOSTcNUOdKSe2S1ku6u6T8trRsg6TblV5hRtJVkp5Ll91Wm+4M1P6xXLuZ2XvXkCEgKQ8sBy4juUDMEkkLyuo0ATcDiyPiDOD6tPx8YDHJZSXPBM4BLkgvOfk14FNp/ZMkfapmvTIzs6pUcyRwLtAREZsjohu4B7iirM61wPKI2AUQETvS8gAmAg3ABKAe2A6cBrwUEV1pvX8BfnU0HTEzs+GrJgRmA1tKHnemZaWagWZJT0paI6kVICKeIrmg/Lb0tjoiNgAdwIckzZNUB3wOmFtp45Kuk9Qmqa2rq6tSFTMzG6FqQqDSiHr5NGsd0ARcCCwB7pQ0TdLpwIeBOSTBcbGkT6ZHDF8C7gWeAF4BeqkgIlZEREtEtMycObOK5lbmeWEzs/6qCYFOjv6UPgfYWqHOgxHRExEvAxtJQuFXgDURsS8i9gEPAR8DiIjvR8R5EfHxtP6m0XVlMJ4ZNjOrpJoQWAs0SZovqQG4GlhZVucB4CIASTNIhoc2A6+RTATXSaoHLgA2pPVmpf9OB34fuHP03TEzs+GoG6pCRPRKWgqsBvLAXRGxXtIyoC0iVqbLLpXUDhSAGyNip6T7gYuB50lGZB6OiO+nq/6GpI+k95dFxEu17ZqZmQ1lyBAAiIhVwKqysltK7gdwQ3orrVMAfm+AdS4ZbmNHwyeLmZn1l4kzhn2ymJlZZZkIATMzq8whYGaWYRkKAU8KmJmVy0QIeErAzKyyTISAmZlV5hAwM8swh4CZWYZlJgR8spiZWX+ZCAGfLGZmVlkmQsDMzCpzCJiZZVhmQsBTAmZm/WUiBOTTxczMKspECJiZWWUOATOzDKsqBCS1StooqUPSTQPUuVJSu6T1ku4uKb8tLdsg6XYp+cKmpCWSnpf0nKSH08tSjpnwiQJmZv0MGQKS8sBy4DJgAbBE0oKyOk3AzcDiiDgDuD4tPx9YDCwEzgTOIb3mMPAN4KKIWAg8ByytVaf692Gs1mxm9t5WzZHAuUBHRGyOiG7gHuCKsjrXAssjYhdAROxIywOYCDQAE4B6YDvJD3sKmJweGRwPbB1lX8zMbJiqCYHZwJaSx51pWalmoFnSk5LWSGoFiIingMeAbeltdURsiIge4EskF6DfSnKE8beVNi7pOkltktq6urqG0TUzMxtKNSFQaTClfIC9DmgCLgSWAHdKmibpdODDwByS4LhY0icl1ZOEwFnAB0iGg26utPGIWBERLRHRMnPmzCqaa2Zm1aqrok4nMLfk8Rz6D910AmvST/gvS9rIkVBYExH7ACQ9BHwMOAAQET9Py+8DKk4414qnhc3M+qvmSGAt0CRpvqQG4GpgZVmdB4CLANJv+TQDm4HXSCeC00//FwAbgNeBBZL6PtpfkpaPCc8Lm5lVNuSRQET0SloKrAbywF0RsV7SMqAtIlamyy6V1A4UgBsjYqek+4GLScb+A3g4Ir4PIOlPgB9J6gFeBX6z9t0zM7PBVDMcRESsAlaVld1Scj+AG9JbaZ0C8HsDrPMO4I5httfMzGooM2cM+1wxM7P+MhEC8tliZmYVZSIEzMysMoeAmVmGOQTMzDIsMyHgXxE1M+svMyFgZmb9OQTMzDLMIWBmlmGZCQHPCJiZ9ZeJEPC5YmZmlWUiBMzMrDKHgJlZhmUnBDwpYGbWTyZCQL6sjJlZRZkIATMzq6yqEJDUKmmjpA5JFa8FLOlKSe2S1ku6u6T8trRsg6TblZgi6dmS25uSvl6rTpmZWXWGvLKYpDywnOQ6wJ3AWkkrI6K9pE4TcDOwOCJ2SZqVlp8PLAYWplX/HbggIv4NWFTy/GeA79akR2ZmVrVqjgTOBToiYnNEdAP3AFeU1bkWWB4RuwAiYkdaHsBEoAGYANQD20ufmAbILOCJkXZiKBIU/QNyZmb9VBMCs4EtJY8707JSzUCzpCclrZHUChARTwGPAdvS2+qI2FD23CXAvTHAz3xKuk5Sm6S2rq6uKprbX11OFBwCZmb9VBMClb5aU/6OWgc0AReSvKnfKWmapNOBDwNzSILjYkmfLHvu1cB3Btp4RKyIiJaIaJk5c2YVze0vlxOFokPAzKxcNSHQCcwteTwH2FqhzoMR0RMRLwMbSULhV4A1EbEvIvYBDwEf63uSpI8AdRHxzCj6MKS6nOh1CJiZ9VNNCKwFmiTNl9RA8sl9ZVmdB4CLACTNIBke2gy8BlwgqU5SPXABUDoctIRBjgJqJScRAUUHgZnZUYYMgYjoBZYCq0newO+LiPWSlkn6bFptNbBTUjvJHMCNEbETuB/4OfA8sA5YFxHfL1n9lRyDEKjLJSNanhcwMzvakF8RBYiIVcCqsrJbSu4HcEN6K61TAH5vkPWeNpzGjlSuLwSKQX3+WGzRzOy9IRNnDNeVhICZmR2RiRDIezjIzKyibIVAwSFgZlYqWyHgIwEzs6NkKwQ8J2BmdpRshIAcAmZmlWQiBOrySTd7CsVxbomZ2btLJkJgysTkdIi9B3vHuSVmZu8umQiBqZPqAdh9oGecW2Jm9u6SiRCY1li7ENjy1n4efuGNUa/HzOzdoKqfjXivmzVlIgBb3z4w6nV94rbHANiwrJVJDf4NCjN7b8vEkcAJkxuYNWUCL7y+u2brXPaD9TVbl5nZeMlECAB8omkmj7Zvp3PX/pqs7ztPbxm6kpnZu1xmQmDpxaeTk/jsN5/k9h9uYv3W3b6+gJllnga4tO+7UktLS7S1tY34+Zu272XZD9p5YtObAExuyHP6rOM4fdYU5kyfxMlTJ3LS1InJv1MmMnVS/eGfoe4z76Z/7rfev7rqI/zHD5/EcRPqkCpdjXNoB7oLnmMwszEh6ZmIaKm4rJoQSC8c/w0gD9wZEX9Roc6VwFdIrj+8LiK+kJbfBlxOctTxKPAHERHpVcq+SXJd4iLw5Yj4p8HaMdoQ6LNt9wGe+vlOnuvcTceOfXTs2Mf2vQcp3xU5wbTGBqY11jO9sYHpjQ38y4bto9r25QtP5tIFJ7Fo7jROnjqJ+rzYsG0vn7n9CVZ88aNcesYvjGr9ZmblRhUCkvLAS8AlJNcSXgssiYj2kjpNwH3AxRGxS9KsiNgh6Xzga0DfxeX/Hbg5Iv5N0p8A+Yj4n5JywAkR8eZgbalVCFTSUyiyY+8h3th9kDd2H2T7noO8vb+bt/Z3s2t/D7veOfLvF847hS+cdwotf/YvNW3DCZMb+OYXzjocONMa65mYXgUnIujcdYC5JzTWdJtm9v43WAhU8xXRc4GOiNicruwe4AqgvaTOtcDyiNgFEBE70vIAJgINgIB6oO+j9G8DH0rrF4FBA2Cs1edzzJ42idnTJlX9nFf+4vJBlxeKwVvvdLNp+17+veNNvvez19m2++CA9d96p5sv/M1PjiqbWJ9jemPD4edNnVTPmbOPZ9qkBo6fVM/USfVMa0z+/d7PXuesU6bx8dNOZOqk+sPLj59YT0NdjojglZ37mT9jctV9NLP3t2pCYDZQ+lWYTuC8sjrNAJKeJBky+kpEPBwRT0l6DNhGEgLfjIgNkqalz/tTSReSXId4aUSMbqzlXSafEzOnTGDmlAmcf/oM/qj1QwPW3XOwh9d3HWDX/m527+9Jjjr2d/P2/m7e3t/D1t0HeLJjJ2fOPp4D3QXe2L2H3Qd62H2gh56S6yQ8/fJb/N/HN/db/6T6PAd6CgDU58XZp0zvFxRTJ9Wx+0AvP3xxO9ecdyrHTawjnxN1OaX/5sjnxJa39vPohu18/qNzmFCfJy+REyj9N5cTW98+wOMbu/h8y1wm1Of6raMuJ/Yd6uW7P32dz531ASbV58mndXISuVyyLoD71nbSeuYvMGViHXX5ZLk4sj0hnujoYv6MycyZ3khDPkddPtlG6RzNazv3s/OdQ/zi7Knky5b1KRSDZ7e8zUdPnT7oa/v62weY3JBnWmPDgHWqPXo72FOgGEFjw+D/HXsKxX59Gmi7I52bsuypZjjo88CnI+J308dfBM6NiP9WUucHQA/JhePnAE8AZwIzSOYSrkqrPgr8MclRRBfwaxHxT5JuAM6KiC9W2P51wHUAp5xyykdfffXVkff2fSgiONBT4O39Pezc101DXY59h3rZc6CHPQeTkNiThsX2PYdYuW4rFzTP5EBPIamTLnunuzDeXRkTfYFTl9NRfZSSo7/6vnDKJ0G1Y++hw3WmTEhCpz6fo/w9dfuepN5Jx0+gLpejoS6XvkEfqfPS9n2H2/DBmZOpz+eoS7eZyyVBlpN4avNOABbNnUZ9ur2+ekmY5ShG8FB6pvoFzTOpT8vr8qIhn0tDDTa+sZd1nbv58MnH0zTruKT9ab36tI8BPNnxJi++sZfLF57M9MZ66nK5ZJ2Ht5s8Z83mt/jRS1385vnzaGzIH7W8Pn9k361/fTc/fHEHS86Zy+QJdYf3Z9/28+n9Xe9088CzW/nUh2Zx4nETDod1XclrUZ/PkcuJv/nRZj566nROn3XckQ8ReZHPlX6oED96qYtDhSKLPzjj8LqS9RxZXz4nDvYUuPsnr/G5s2YzqT5/ZNu53FH16vPimVd3se9QL4vmTjt6WS5HPn/kbyqfEw88+zrnzj+R4ybUHdkn6TpLHegu8NPXdnH+B08cMqT3Huxhx95DfHDmccP5cx/QaOcEPk7yyf7T6eObASLiz0vq3AGsiYi/Sx//ELiJZNJ3YkT8aVp+C3CQZJ5gHzAlIoqS5gIPR8QZg7VlLOcEsq63UGTPwd7DoTBlYh3dhSKFYlAoBr19/xaC3mKRvQd7mTN9Ej2FIsWAYjEoRhJKxYDeYpHtew4yd3ojhwpFCoVkHcXoW1eRnkLw4ra9nHfaCfQUivQWkuWFYhCRXASoGMEzr+7ivPknANBdCCKS5RFBAMWAZ7e8zfwTG5na2JCuK1l/oRj0FJN1b+7ax96DvVzQPJOeQvGodvUWk74e6C7wwLNb+Z1fmk9E8um70q/P/uuLO5hx3AQWzplKd9r28nr7DvXyxKY3aU0n+3uLRboLQW+hSDHdTwQ8/cpbAHyiacbh9fQUk3p9+76nUOTVnck5Lh+ZM5We9HXoLcTh1wlg1/5uDvYUmdZYz7RJ9UfV6ykU6S0GgsOBOL2xHkmH939v+rqUa8jnDr92Vh2JwyFTlxN7Dx35AcucOBKUJR9C+u6/9lbyWk8rCei7r/3YiIdyRzsnsBZokjQfeB24GvhCWZ0HgCXA30maQTI8tBk4DbhW0p+TDAddAHw9/XbQ90lC4l+BT3H0HIMdY3X5HCdMbuCEyQMPb4yXXz/v1GO6va9ffdYx3d67TcTRwV+fT450+pb1lnwY6C0cCdnJE+qYWJ9LlyUh1hdghWIcDqSGfI7jJ9UfDqZC8Uj4FIpHwmrfoV7mTk/m6Pq2edQHkjS49x7spS4nTjyu4ah1lG6z737Hjn2cN/+EI8tLPpAUStq85a0DNDbkOW3m5CP9KR4JyiP7IHj8pS4uXXASE+pyh9uXtLWYrj9pz76DvTzSvp3fPH9eSb3iUR9C+tox47gGfvra23z2Ix9I+lAoMnnC2HyFfMgQiIheSUuB1STj/XdFxHpJy4C2iFiZLrtUUjtQAG6MiJ2S7gcuBp4nmSR+OCK+n676j4F/kPR1kqGh36p158xs+KR0GKrCe46kdMgKkreD/iZk4hfJjrjhkuaq635tDNsxUpk6WczMLIsGGw7KzM9GmJlZfw4BM7MMcwiYmWWYQ8DMLMMcAmZmGeYQMDPLMIeAmVmGvafOE5DUBYz0x4NmMM6/VDoAt2t43K7hcbuG5/3arlMjYmalBe+pEBgNSW0DnSwxntyu4XG7hsftGp4stsvDQWZmGeYQMDPLsCyFwIrxbsAA3K7hcbuGx+0ansy1KzNzAmZm1l+WjgTMzKyMQ8DMLMPe9yEgqVXSRkkdkm46BtubK+kxSRskrZf0B2n5VyS9LunZ9PaZkufcnLZvo6RPj1XbJb0i6fl0+21p2QmSHpW0Kf13elouSben235O0tkl6/mNtP4mSb8xyjb9h5J98qykPZKuH6/9JekuSTskvVBSVrN9JOmj6WvQkT63qivCD9Cur0l6Md329yRNS8vnSTpQsu/uGGr7A/VxhO2q2Wsnab6kn6TtuldSVZe+G6Bd95a06RVJzx7L/aWB3xvG9+8ruV7r+/NGcumjn5Nc5rIBWAcsGONtngycnd6fArwELAC+AvyPCvUXpO2aAMxP25sfi7YDrwAzyspuA25K798E3Jre/wzwEMllQT8G/CQtP4Hk0qEnANPT+9Nr+Hq9AZw6XvsL+CRwNvDCWOwj4Gng4+lzHgIuG0W7LgXq0vu3lrRrXmm9svVU3P5AfRxhu2r22gH3AVen9+8AvjTSdpUt/0vglmO5vxj4vWFc/77e70cC5wIdEbE5IrqBe4ArxnKDEbEtIn6a3t8LbABmD/KUK4B7IuJQRLwMdKTtPlZtvwL4Vnr/W8DnSsr/PhJrgGmSTgY+DTwaEW9FxC7gUaC1Rm35FPDziBjsrPAx3V8R8SPgrQrbHPU+SpcdHxFPRfI/9u9L1jXsdkXEIy9kEy8AAANPSURBVBHRd/XyNcCcwdYxxPYH6uOw2zWIYb126afYi4H7a9mudL1XAt8ZbB213l+DvDeM69/X+z0EZgNbSh53Mvgbck1JmgecBfwkLVqaHtbdVXL4OFAbx6LtATwi6RlJ16VlJ0XENkj+SIFZ49CuPldz9H/M8d5ffWq1j2an98eijb9N8smvz3xJP5P0uKRPlLR3oO0P1MeRqsVrdyLwdknQ1Wp/fQLYHhGbSsqO6f4qe28Y17+v93sIVBoPOybfiZV0HPBPwPURsQf4P8AHgUXANpLD0cHaOBZtXxwRZwOXAf9V0icHqXss20U61vtZ4B/TonfD/hrKcNsyVvvuy0Av8O20aBtwSkScBdwA3C3p+LHafgW1eu3Gqr1LOPrDxjHdXxXeGwasOsD2a7q/3u8h0AnMLXk8B9g61huVVE/yIn87Ir4LEBHbI6IQEUXgb0gOgQdrY83bHhFb0393AN9L27A9PYzsO/zdcazblboM+GlEbE/bOO77q0St9lEnRw/ZjLqN6aTgfwJ+PR0CIB1u2Znef4ZkvL15iO0P1Mdhq+Fr9ybJEEhdhfaOSLqu/wzcW9LeY7a/Kr03DLKuY/P3NdSkwXv5BtSRTJrM58iE0xljvE2RjMV9vaz85JL7f0gyNgpwBkdPlm0mmSiraduBycCUkvs/JhnL/xpHT0rdlt6/nKMnpZ6OI5NSL5NMSE1P759Qg/12D/Bb74b9RdlEYS33EbA2rds3cfeZUbSrFWgHZpbVmwnk0/unAa8Ptf2B+jjCdtXstSM5MiydGP79kbarZJ89Ph77i4HfG8b172vM3gzfLTeSGfaXSNL9y8dge79Ecgj2HPBsevsM8A/A82n5yrL/KF9O27eRktn8WrY9/eNel97W962PZNz1h8Cm9N++PyYBy9NtPw+0lKzrt0km9TooeeMeRdsagZ3A1JKycdlfJMME24Aekk9Wv1PLfQS0AC+kz/km6Vn7I2xXB8nYcN/f2R1p3V9NX+N1wE+BXx5q+wP1cYTtqtlrl/7dPp329R+BCSNtV1r+d8B/Kat7TPYXA783jOvfl382wswsw97vcwJmZjYIh4CZWYY5BMzMMswhYGaWYQ4BM7MMcwiYmWWYQ8DMLMP+PybPNCrYLSc7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 51.24999999999999 % \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape) \n",
    "print(Y_train.shape)\n",
    "parameters = l_nn(X_train, Y_train.T, [10, 20, 1], 0.1, 20000, print_t=True, regularization=\"L2\", regulizer=0)\n",
    "acc = predict(X_test, parameters, Y_test.T, \"L2\", 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc == Y_test.T).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
